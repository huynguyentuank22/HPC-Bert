from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from xgboost import XGBClassifier, XGBRegressor
from sklearn.metrics import classification_report, mean_absolute_error
import os 
from tqdm import tqdm
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import torch
from catboost import CatBoostClassifier, CatBoostRegressor

if __name__ == "__main__":
    print("Device:", "cuda" if torch.cuda.is_available() else "cpu")

    # === Paths ===
    result_path = "baseline_results"
    os.makedirs(result_path, exist_ok=True)
    
    data_folder = "data_train"
    emb_folder = "data_embedding_semantic"
    os.makedirs(emb_folder, exist_ok=True)
    
    test_yms = ["24_04"]
    regression_metric = lambda y_true, y_pred: f"MAE: {mean_absolute_error(y_true, y_pred):.4f}"

    # === Tasks ===
    tasks = {
        "ec": {"type": "classification", "target": lambda j: 1 if j["exit state"] == "completed" else 0},
        "pclass": {"type": "classification", "target": lambda j: 1 if j.pclass == "compute-bound" else 0},
        "avgpcon": {"type": "regression", "target": lambda j: int(j.avgpcon / j.nnuma)},
        "duration": {"type": "regression", "target": lambda j: int(j.duration / 60)}
    }

    # === Only using semantic embeddings ===
    features = {"sb_anon": lambda df: np.vstack(df["embedding_anon"].values)}

    # === Model candidates ===
    model_candidates = {
    "classification": {
        # "KNN": KNeighborsClassifier,
        # "RF":  RandomForestClassifier,
        # "XGB": XGBClassifier,
        "CatBoost": CatBoostClassifier
    },
    "regression": {
        # "KNN": KNeighborsRegressor,
        # "RF":  RandomForestRegressor,
        # "XGB": XGBRegressor,
        "CatBoost": CatBoostRegressor
    }
}

    # === Define multiple semantic templates ===
    semantic_templates = [
        # Template 1: C·∫•u tr√∫c b·ªã ƒë·ªông r√∫t g·ªçn (Compact Passive Construction)
        # Di·ªÖn ƒë·∫°t h√†nh ƒë·ªông ‚Äúsubmit‚Äù ·ªü d·∫°ng b·ªã ƒë·ªông nh·∫±m ƒëa d·∫°ng h√≥a ng·ªØ ph√°p v√† tr·∫≠t t·ª± th√¥ng tin.
        # C√¢u m√¥ t·∫£ ng·∫Øn g·ªçn, ƒë∆∞a "Job" l√™n ƒë·∫ßu ƒë·ªÉ nh·∫•n m·∫°nh ƒë·ªëi t∆∞·ª£ng c√¥ng vi·ªác, ƒë·ªìng th·ªùi v·∫´n gi·ªØ ƒë·ªß ba th·ª±c th·ªÉ: user ‚Äì job ‚Äì environment.
        lambda r: f"Job submitted by user {r['usr']} with name {r['jnam']} requiring environment {r['jobenv_req']}.",

        # Template 2: T·∫≠p trung v√†o Ch·ªß th·ªÉ/H√†nh ƒë·ªông c∆° b·∫£n (User‚ÄìJob‚ÄìEnvironment Relation)
        # M√¥ t·∫£ tr·ª±c ti·∫øp m·ªëi quan h·ªá gi·ªØa ng∆∞·ªùi d√πng (user), c√¥ng vi·ªác (job) v√† m√¥i tr∆∞·ªùng t√≠nh to√°n (environment).
        # C·∫•u tr√∫c ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu, gi√∫p m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c ng·ªØ c·∫£nh c∆° b·∫£n c·ªßa h√†nh ƒë·ªông ‚Äúsubmit‚Äù.
        lambda r: f"The user profile {r['usr']} submitted a computation {r['jnam']} to the environment {r['jobenv_req']}.",
        
        # Template 3: T·∫≠p trung v√†o Ng·ªØ c·∫£nh/M√¥i tr∆∞·ªùng (Environment Focus)
        # Nh·∫•n m·∫°nh r·∫±ng m√¥i tr∆∞·ªùng ƒë∆∞·ª£c y√™u c·∫ßu cho m·ªôt t√°c v·ª• c·ª• th·ªÉ c·ªßa ng∆∞·ªùi d√πng.
        lambda r: f"The high-priority computational environment {r['jobenv_req']} was specifically requested by user {r['usr']} for running the job named {r['jnam']}.",
        
        # Template 4: T·∫≠p trung v√†o ƒê·ªëi t∆∞·ª£ng/C√¥ng vi·ªác (Job Focus)
        # Nh·∫•n m·∫°nh t√≠nh ch·∫•t c·ªßa Job v√† vai tr√≤ c·ªßa User/Environment ƒë·ªëi v·ªõi Job ƒë√≥.
        lambda r: f"Job {r['jnam']}, which will be executed by {r['usr']}, requires exclusive access to the infrastructure {r['jobenv_req']}.",
        
        # Template 5: M·ªëi quan h·ªá H√†nh ƒë·ªông & Li√™n k·∫øt (Action & Association)
        # D√πng c√°c ƒë·ªông t·ª´ m·∫°nh h∆°n ƒë·ªÉ m√¥ t·∫£ h√†nh ƒë·ªông l·∫≠p l·ªãch/ch·∫°y.
        lambda r: f"The scheduling system recorded that {r['usr']} is deploying job {r['jnam']} onto the {r['jobenv_req']} partition.",
        
        # Template 6: C√∫ ph√°p b·ªã ƒë·ªông (Passive Voice)
        # Th·ª≠ nghi·ªám c√°c c·∫•u tr√∫c c√¢u kh√°c ƒë·ªÉ bu·ªôc m√¥ h√¨nh h·ªçc c√°c ph·ª• thu·ªôc kh√°c.
        lambda r: f"The hardware configuration {r['jobenv_req']} is being utilized by job {r['jnam']} which was initialized by {r['usr']}."
    ]

    # === Load SBERT once ===
    print("Loading SBERT model...")
    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')

    # === Iterate through each template ===
    for template_idx, template_fn in enumerate(semantic_templates, start=1):
        print(f"\nüîπ Running Semantic Template {template_idx}/{len(semantic_templates)} ...")

        # Prepare storage
        x_train, y_train, x_test, y_test = (
            {f: [] for f in features},
            {t: [] for t in tasks},
            {f: [] for f in features},
            {t: [] for t in tasks}
        )

        # === Load data and generate embeddings for current template ===
        for data_path in tqdm([
            os.path.join(data_folder, f) for f in os.listdir(data_folder)
            if os.path.isfile(os.path.join(data_folder, f)) and f.endswith(".parquet")
        ]):
            df = pd.read_parquet(data_path)
            ym = os.path.basename(data_path).split(".parquet")[0]

            emb_save_path = os.path.join(emb_folder, f"{ym}_template{template_idx}.parquet")

            if os.path.exists(emb_save_path):
                emb_df = pd.read_parquet(emb_save_path)
                df = pd.concat([df.reset_index(drop=True), emb_df.reset_index(drop=True)], axis=1)
                print(f"‚úÖ Loaded cached embeddings for template {template_idx}, {ym}")
            else:
                print(f"Generating embeddings for {ym} using template {template_idx}...")
                df["merged_text"] = df.apply(template_fn, axis=1)
                embeddings = sbert_model.encode(
                    df["merged_text"].tolist(),
                    batch_size=256,
                    show_progress_bar=True,
                    device="cuda" if torch.cuda.is_available() else "cpu"
                )
                df["embedding_anon"] = list(embeddings)

                emb_df = df[["embedding_anon"]].copy()
                emb_df.to_parquet(emb_save_path)
                print(f"‚úÖ Saved embeddings: {emb_save_path}")

            for feat in features:
                x_values = list(features[feat](df))
                if ym in test_yms:
                    x_test[feat] += x_values
                else:
                    x_train[feat] += x_values

            for task in tasks:
                y_values = df.apply(tasks[task]["target"], axis=1).tolist()
                if ym in test_yms:
                    y_test[task] += y_values
                else:
                    y_train[task] += y_values

        # === Train and evaluate models for current template ===
        print(f"\nüèÅ Training models for template {template_idx}...\n")
        for feat in features:
            for task in tasks:
                task_type = tasks[task]["type"]

                for model_name, model_cls in model_candidates[task_type].items():
                    print(f"‚ñ∂ Template {template_idx} | {model_name} | {task} ({task_type})")

                    model_instance = model_cls(n_jobs=-1) if model_name != "CatBoost" else model_cls(task_type="GPU") if torch.cuda.is_available() else model_cls(thread_count=-1)
                    model_instance.fit(x_train[feat], y_train[task])
                    y_pred = model_instance.predict(x_test[feat])

                    if task_type == "classification":
                        report = classification_report(y_test[task], y_pred)
                    else:
                        report = regression_metric(y_test[task], y_pred)

                    result_file = os.path.join(
                        result_path, f"{model_name}_{feat}_template{template_idx}_{task}.txt"
                    )
                    with open(result_file, "w", encoding="utf-8") as f:
                        f.write(report)

                    print(f"‚úÖ Saved result to {result_file}")

    print("\nüéØ All templates completed successfully!")
